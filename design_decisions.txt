## Problem Statement

We're building a sync service that synchronizes records from internal systems to external systems (potentially multiple). The core challenges we're solving are:

- Schema transformation between different data formats
- Synchronization to external services with rate limiting
- Handling multiple external systems efficiently

## Key Assumptions

1. Database exists and all changes are streamed through a system like Kafka or Kinesis
2. External systems are operational with valid API endpoints
3. Currently dealting with one record type called 'Contact'
3. Internal 'Contact' data has a type field that determines routing

## Architecture Overview

The service consumes a stream of contact events from an internal database. Each contact record includes a type field that determines which external system receives the data. Based on this type, we perform schema transformation and route to the appropriate external system.

## Core Design Decisions

### 1. Internal Database Updates: Streaming vs Polling

Choice: Streaming updates
Why: Polling would require constant API calls even when no updates exist, and could overwhelm the database during large change periods. Streaming provides async processing without impacting database performance.

### 2. Schema Transformation: Pydantic Models vs Config-Driven Mapping

Choice: Pydantic-based models
Why: While static mapping is simpler, Pydantic provides strong typing, validation, and better support for custom business logic.

### 3. API Dispatcher Retry Logic

Choice: Exponential backoff with jitter
Why: Jitter adds randomness to prevent thundering herd problems

### 4. Multiple External System Strategy

Choice: Adapter pattern with routing
Why: Provides consistent interfaces while allowing system-specific optimizations and easy addition of new external systems.

### 5. Hardcoded vs External Configuration

Choice: External Configuration
Why External Config is Better: Environment flexibility, runtime changes, security, maintenance

### 6. Synchronous vs Async Processing

Choice: Async Processing
Why Async is Better: Resource efficiency, simpler code, better performance for I/O-bound tasks

### 7. Direct Instantiation vs Factory Pattern

Choice:: Factory Pattern
Why Factory Pattern is Better: Preset configurations, easier testing, deployment flexibility


## Detailed Architecture Choices

### Pipeline Architecture
- Multi-stage pipeline with queues between stages
- Decoupled processing with buffering and parallel execution
- Three queues: raw events → processed events → transformed data -> api dispatcher

### Service Separation
- MockStreamGenerator: Event generation for testing
- InternalEventConsumer: Event processing and filtering
- SchemaTransformer: Data transformation between schemas
- APIDispatcherService: External API communication

### Async/Concurrent Design
- Full async implementation using asyncio
- Non-blocking I/O for external API calls
- High throughput with separate tasks for each pipeline stage

### Data Models & Validation
- Pydantic models for all data structures
- Runtime validation and automatic serialization
- Event-driven architecture with audit trail and replay capability

### External System Integration
- Adapter pattern for each external system (Salesforce, HubSpot)
- Routing by contact type: Leads/Prospects → Salesforce, Customers/Vendors → HubSpot
- Consistent interface across all external systems

### Error Handling & Resilience
- Graceful degradation: Continue processing even if some events fail
- Configurable retries for external API calls
- Comprehensive error logging and queue-based buffering

### Configuration & Flexibility
- Factory pattern for different pipeline configurations
- Externalized configuration for all components
- Preset configurations for testing and different deployment scenarios

### Performance & Scalability
- Queue-based buffering between pipeline stages
- Batch processing for efficiency
- Backpressure handling and smooth data flow